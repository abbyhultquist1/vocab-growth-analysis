{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22bd223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import tkinter as tkinter\n",
    "\n",
    "from tkinter import filedialog as tkfiledialog\n",
    "\n",
    "ENTRY_WIDTH = 20  # width of text entry field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ff5a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.executable: /usr/local/bin/python3\n",
      "sys.version: 3.14.2 (v3.14.2:df793163d58, Dec  5 2025, 12:18:06) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "pandas available: True\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/abbyhultquist/Library/Python/3.14/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/abbyhultquist/Library/Python/3.14/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/abbyhultquist/Library/Python/3.14/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/abbyhultquist/Library/Python/3.14/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib\n",
    "print(\"sys.executable:\", sys.executable)\n",
    "print(\"sys.version:\", sys.version)\n",
    "print(\"pandas available:\", importlib.util.find_spec(\"pandas\") is not None)\n",
    "# safe install using the kernel's interpreter\n",
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pandas\"])\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed84173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.executable: /usr/local/bin/python3\n",
      "sys.version: 3.14.2 (v3.14.2:df793163d58, Dec  5 2025, 12:18:06) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "pandas available: True\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib\n",
    "print(\"sys.executable:\", sys.executable)\n",
    "print(\"sys.version:\", sys.version)\n",
    "print(\"pandas available:\", importlib.util.find_spec(\"pandas\") is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5da49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_THRESHOLD = 0.8\n",
    "import pandas as pd\n",
    "sim = pd.read_csv(\"/Users/abbyhultquist/Documents/First Year Project/nouns.csv\", index_col=0)\n",
    "\n",
    "\n",
    "# builds a list of edges where similarity >= 0.9, in the variable `edges`\n",
    "edges = []\n",
    "for w1 in sim.index:\n",
    "    for w2 in sim.columns:\n",
    "        if w1 != w2 and sim.loc[w1, w2] >= SIM_THRESHOLD:\n",
    "            edges.append((w1, w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dddfb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: 1 matching indices: [0]\n",
      "{'child_id': 4139, 'study id': 'LTP102', 'study': 'Long-1', 'gender': 'F', 'age': 16.9953977646285, 'birthday': '2008/10/17', 'session_date': '2010/03/18', 'session_num': 1, 'total num sessions': 12, 'words_spoken': 91.0, 'items excluded': 0, 'percentile': 63.6363636363636, 'extra categories': 2, 'revision': 0, 'languages': 'english', 'num languages': 1, 'cdi type': 'fullenglishmcdi', 'hard of hearing': 0, 'deleted': 0, 'vocab_size': 91.0, 'Talker_Type': 'TT', 'baa baa': 1, 'choo choo': 0, 'cockadoodledoo': 0, 'grr': 0, 'meow': 0, 'moo': 1, 'ouch': 0, 'quack quack': 0, 'uh oh': 0, 'vroom': 0, 'woof woof': 0, 'yum yum': 1, 'alligator': 0, 'animal': 0, 'ant': 0, 'bear': 1, 'bee': 0, 'bird': 1, 'bug': 0, 'bunny': 0, 'butterfly': 0, 'cat': 1, 'chicken(animal)': 0, 'cow': 0, 'deer': 0, 'dog': 1, 'donkey': 0, 'duck': 1, 'elephant': 0, 'fish(animal)': 1, 'frog': 1, 'giraffe': 0, 'goose': 0, 'hen': 0, 'horse': 0, 'kitty': 0, 'lamb': 0, 'lion': 0, 'monkey': 0, 'moose': 0, 'mouse': 0, 'owl': 0, 'penguin': 0, 'pig': 1, 'pony': 0, 'puppy': 0, 'rooster': 0, 'sheep': 1, 'squirrel': 0, 'teddybear': 0, 'tiger': 0, 'turkey': 0, 'turtle': 0, 'wolf': 0, 'zebra': 0, 'airplane': 0, 'bicycle': 0, 'boat': 0, 'bus': 0, 'car': 1, 'fire truck': 0, 'helicopter': 0, 'motorcycle': 0, 'sled': 0, 'stroller': 1, 'tractor': 0, 'train': 0, 'tricycle': 0, 'truck': 0, 'ball': 1, 'balloon': 1, 'bat': 0, 'block': 0, 'book': 1, 'bubbles': 0, 'chalk': 0, 'crayon': 0, 'doll': 1, 'game': 0, 'glue': 0, 'pen': 0, 'pencil': 0, 'play dough': 0, 'present': 0, 'puzzle': 0, 'story': 0, 'toy': 0, 'apple': 1, 'applesauce': 0, 'banana': 1, 'beans': 0, 'bread': 1, 'butter': 0, 'cake': 0, 'candy': 0, 'carrots': 0, 'cereal': 1, 'cheerios': 1, 'cheese': 1, 'chicken(food)': 0, 'chocolate': 0, 'coffee': 0, 'coke': 0, 'cookie': 1, 'corn': 0, 'cracker': 1, 'donut': 0, 'drink(noun)': 0, 'egg': 1, 'fish(food)': 0, 'food': 1, 'french fries': 0, 'grapes': 1, 'green beans': 0, 'gum': 0, 'hamburger': 0, 'ice': 0, 'ice cream': 0, 'jello': 0, 'jelly': 0, 'juice': 0, 'lollipop': 0, 'meat': 0, 'melon': 0, 'milk': 1, 'muffin': 1, 'noodles': 0, 'nuts': 0, 'orange(noun)': 1, 'pancake': 0, 'peanut butter': 0, 'peas': 0, 'pickle': 0, 'pizza': 0, 'popcorn': 0, 'popsicle': 0, 'potato': 1, 'potato chip': 0, 'pretzel': 0, 'pudding': 0, 'pumpkin': 0, 'raisin': 0, 'salt': 0, 'sandwich': 0, 'sauce': 0, 'soda/pop': 0, 'soup': 0, 'spaghetti': 0, 'strawberry': 1, 'toast': 0, 'tuna': 0, 'vanilla': 0, 'vitamins': 0, 'water(food)': 1, 'yogurt': 0, 'beads': 0, 'belt': 0, 'bib': 0, 'boots': 1, 'button': 0, 'coat': 0, 'diaper': 1, 'dress': 0, 'gloves': 0, 'hat': 1, 'jacket': 0, 'jeans': 0, 'mittens': 0, 'necklace': 0, 'pajamas': 0, 'pants': 1, 'scarf': 0, 'shirt': 1, 'shoe': 1, 'shorts': 0, 'slipper': 1, 'sneaker': 0, 'snowsuit': 0, 'sock': 1, 'sweater': 0, 'tights': 0, 'underpants': 0, 'zipper': 0, 'ankle': 0, 'arm': 0, 'belly button': 1, 'buttocks/bottom': 0, 'cheek': 1, 'chin': 0, 'ear': 1, 'eye': 1, 'face': 0, 'feet': 0, 'finger': 0, 'hair': 0, 'hand': 0, 'head': 1, 'knee': 0, 'leg': 1, 'lips': 0, 'mouth': 0, 'nose': 1, 'owie/boo boo': 0, 'penis': 0, 'shoulder': 0, 'tooth': 0, 'toe': 0, 'tongue': 0, 'tummy': 1, 'vagina': 0, 'basket': 0, 'blanket': 1, 'bottle': 0, 'box': 0, 'bowl': 0, 'broom': 0, 'brush': 0, 'bucket': 0, 'camera': 0, 'can(noun)': 0, 'clock': 0, 'comb': 0, 'cup': 1, 'dish': 0, 'fork': 0, 'garbage': 0, 'glass': 0, 'glasses': 0, 'hammer': 0, 'jar': 0, 'keys': 0, 'knife': 0, 'lamp': 0, 'light': 0, 'medicine': 0, 'money': 0, 'mop': 0, 'nail': 0, 'napkin': 0, 'paper': 0, 'penny': 0, 'picture': 0, 'pillow': 0, 'plant': 0, 'plate': 0, 'purse': 0, 'radio': 0, 'scissors': 0, 'soap': 0, 'spoon': 0, 'tape': 0, 'telephone': 1, 'tissue/kleenex': 0, 'toothbrush': 0, 'towel': 0, 'trash': 0, 'tray': 0, 'vacuum': 0, 'walker': 0, 'watch(noun)': 0, 'basement': 0, 'bathroom': 1, 'bathtub': 0, 'bed': 1, 'bedroom': 0, 'bench': 0, 'chair': 1, 'closet': 0, 'couch': 0, 'crib': 0, 'door': 1, 'drawer': 0, 'dryer': 0, 'garage': 0, 'high chair': 0, 'kitchen': 0, 'living room': 0, 'oven': 0, 'play pen': 0, 'porch': 0, 'potty': 1, 'refrigerator': 0, 'rocking chair': 0, 'room': 0, 'shower': 0, 'sink': 0, 'sofa': 0, 'stairs': 0, 'stove': 0, 'table': 1, 'tv': 0, 'washing machine': 0, 'window': 0, 'backyard': 0, 'cloud': 0, 'flag': 0, 'flower': 0, 'garden': 0, 'grass': -1, 'hose': 0, 'ladder': 0, 'lawn mower': 0, 'moon': 0, 'pool': 0, 'rain': 0, 'rock': 0, 'roof': 0, 'sandbox': 0, 'shovel': 0, 'sidewalk': 0, 'sky': 0, 'slide(noun)': -1, 'snow': 1, 'snowman': 0, 'sprinkler': 0, 'star': 0, 'stick': 0, 'stone': 0, 'street': 0, 'sun': 0, 'swing(noun)': 0, 'tree': 1, 'water(outside)': 1, 'wind': 1, 'beach': 0, 'camping': 0, 'church': 0, 'circus': 0, 'country': 0, 'downtown': 0, 'farm': 0, 'gas station': 0, 'home': 0, 'house': 0, 'movie': 0, 'outside': 0, 'park': 0, 'party': 0, 'picnic': 0, 'playground': 0, 'school': 1, 'store': 0, 'woods': 0, 'work(place)': -1, 'yard': 0, 'zoo': 0, 'aunt': 0, 'baby': 1, 'babysitter': 0, \"babysitter's name\": 0, 'boy': 0, 'brother': 1, 'child': 0, 'clown': 0, 'cowboy': 0, 'daddy': 0, 'doctor': 0, 'fireman': 0, 'friend': 0, 'girl': 1, 'grandma': 1, 'grandpa': 0, 'lady': 0, 'mailman': 0, 'man': 0, 'mommy': 1, 'nurse': 0, \"child's own name\": 1, 'people': 0, 'person': 0, \"pet's name\": 0, 'police': 0, 'sister': 0, 'teacher': 0, 'uncle': 0, 'bath': 1, 'breakfast': 0, 'bye': 1, 'call (on phone)': 0, 'dinner': 0, 'give me five!': 0, 'gonna get you!': 0, 'go potty': 0, 'hi': 1, 'hello': 0, 'lunch': 0, 'nap': 1, 'night night': 0, 'no': 1, 'patty cake': 0, 'peekaboo': 1, 'please': 1, 'shh/shush/hush': 0, 'shopping': 0, 'snack': 0, 'so big!': 0, 'thank you': 1, 'this little piggy': 0, 'turn around': 0, 'yes': 1, 'bite': 0, 'blow': 0, 'break': 0, 'bring': 0, 'build': 0, 'bump': 0, 'buy': 0, 'carry': 0, 'catch': 0, 'chase': 0, 'clap': 0, 'clean(verb)': 0, 'climb': 0, 'close': 0, 'cook': 0, 'cover': 0, 'cry': 0, 'cut': 0, 'dance': 0, 'draw': 0, 'drink(verb)': 0, 'drive': 0, 'drop': 0, 'dry(verb)': 0, 'dump': 0, 'eat': 1, 'fall': 0, 'feed': 0, 'find': 0, 'finish': 0, 'fit': 0, 'fix': 0, 'get': 0, 'give': 0, 'go': 1, 'hate': 0, 'have': 0, 'hear': 0, 'help': 0, 'hide': 0, 'hit': 0, 'hold': 0, 'hug': 0, 'hurry': 0, 'jump': 0, 'kick': 0, 'kiss': 0, 'knock': 0, 'lick': 0, 'like': 0, 'listen': 0, 'look': 1, 'love': 0, 'make': 0, 'open': 0, 'paint': 0, 'pick': 0, 'play': 0, 'pour': 0, 'pretend': 0, 'pull': 0, 'push': 0, 'put': 0, 'read': 0, 'ride': 0, 'rip': 0, 'run': 0, 'say': 0, 'see': 0, 'shake': 0, 'share': 0, 'show': 0, 'sing': 0, 'sit': 1, 'skate': 0, 'sleep': 1, 'slide(verb)': 0, 'smile': 0, 'spill': 0, 'splash': 0, 'stand': 0, 'stay': 0, 'stop': 0, 'sweep': 0, 'swim': 0, 'swing(verb)': 0, 'take': 0, 'talk': 0, 'taste': 0, 'tear': 0, 'think': 0, 'throw': 0, 'tickle': 0, 'touch': 0, 'wait': 0, 'wake': 0, 'walk': 0, 'wash': 0, 'watch(verb)': 0, 'wipe': 0, 'wish': 0, 'work(verb)': 0, 'write': 0, 'allgone': 1, 'asleep': 0, 'awake': 0, 'bad': 0, 'better': 0, 'big': 0, 'black': 0, 'blue': 0, 'broken': 0, 'brown': 0, 'careful': 0, 'clean(adjective)': 1, 'cold': 1, 'cute': 0, 'dark': 0, 'dirty': 1, 'dry(adjective)': 0, 'empty': 0, 'fast': 0, 'fine': 0, 'first': 0, 'full': 0, 'gentle': 0, 'good': 0, 'green': 0, 'happy': 0, 'hard': 0, 'heavy': 0, 'high': 0, 'hot': 1, 'hungry': 1, 'hurt': 0, 'last': 0, 'little': 0, 'long': 0, 'loud': 0, 'mad': 0, 'naughty': 0, 'new': 0, 'nice': 0, 'noisy': 0, 'old': 0, 'orange(adjective)': 0, 'poor': 0, 'pretty': 0, 'quiet': 0, 'red': 0, 'sad': 0, 'scared': 0, 'sick': 0, 'sleepy': 1, 'slow': 0, 'soft': 0, 'sticky': 0, 'stuck': 0, 'thirsty': 1, 'tiny': 0, 'tired': 0, 'wet': 0, 'white': 0, 'windy': 0, 'yellow': 0, 'yucky': 0, 'after': 0, 'before': 0, 'day': 0, 'later': 0, 'morning': 0, 'night': 0, 'now': 0, 'time': 0, 'today': 0, 'tomorrow': 0, 'tonight': 0, 'yesterday': 0, 'he': 0, 'her': 0, 'hers': 0, 'him': 0, 'his': 0, 'i': 0, 'it': 0, 'me': 0, 'mine': 0, 'my': 0, 'myself': 0, 'our': 0, 'she': 0, 'that': 0, 'their': 0, 'them': 0, 'these': 0, 'they': 0, 'this': 0, 'those': 0, 'us': 0, 'we': 0, 'you': 0, 'your': 0, 'yourself': 0, 'how': 0, 'what': 0, 'when': 0, 'where': 1, 'which': 0, 'who': 0, 'why': 0, 'about': 0, 'above': 0, 'around': 0, 'at': 0, 'away': 0, 'back': 0, 'behind': 0, 'beside': 0, 'by': 0, 'down': 0, 'for': 0, 'here': 0, 'inside/in': 0, 'into': 0, 'next to': 0, 'of': 0, 'off': 0, 'on': 0, 'on top of': 0, 'out': 0, 'over': 0, 'there': 0, 'to': 0, 'under': 0, 'up': 0, 'with': 0, 'a': 0, 'all': 0, 'a lot': 0, 'an': 0, 'another': 0, 'any': 0, 'each': 0, 'every': 0, 'more': 0, 'much': 0, 'not': 0, 'none': 0, 'other': 0, 'same': 0, 'some': 0, 'the': 0, 'too': 0, 'am': 0, 'are': 0, 'be': 0, 'can(verb)': 0, 'could': 0, 'did/did ya': 0, 'do': 0, 'does': 0, \"don't\": 0, 'gonna/going to': 0, 'gotta/got to': 0, 'hafta/have to': 0, 'is': 0, 'lemme/ let me': 0, 'need/need to': 0, 'try/try to': 0, 'wanna/want to': 0, 'was': 0, 'were': 0, 'will': 0, 'would': 0, 'and': 0, 'because': 0, 'but': 0, 'if': 0, 'so': 0, 'then': 0, 'Unnamed: 699': nan, 'Unnamed: 700': nan, 'Unnamed: 701': nan, 'Unnamed: 702': nan, 'Unnamed: 703': nan, 'Unnamed: 704': nan, 'Unnamed: 705': nan, 'Unnamed: 706': nan, 'Unnamed: 707': nan}\n"
     ]
    }
   ],
   "source": [
    "# load (no index_col) or reset index if already loaded with index_col=0\n",
    "cdi = pd.read_csv(\"/Users/abbyhultquist/Documents/First Year Project/CDI_cleaned.csv\")\n",
    "# or if already read with index_col=0: cdi = cdi.reset_index()\n",
    "\n",
    "# normalize and coerce key columns\n",
    "cdi.columns = cdi.columns.str.strip()\n",
    "cdi['child_id'] = pd.to_numeric(cdi['child_id'], errors='coerce')\n",
    "cdi['session_num'] = pd.to_numeric(cdi['session_num'], errors='coerce')\n",
    "\n",
    "child_id = 4139\n",
    "session_num = 1\n",
    "\n",
    "mask = (cdi['child_id'] == int(child_id)) & (cdi['session_num'] == int(session_num))\n",
    "print(\"matches:\", mask.sum(), \"matching indices:\", cdi.index[mask].tolist())\n",
    "\n",
    "rows = cdi.loc[mask]\n",
    "if rows.empty:\n",
    "    raise ValueError(f\"No rows match child_id={child_id} session_num={session_num}\")\n",
    "row = rows.iloc[0]\n",
    "print(row.to_dict())\n",
    "\n",
    "row = cdi[\n",
    "    (cdi.child_id == child_id) &\n",
    "    (cdi.session_num == session_num)\n",
    "].iloc[0]\n",
    "\n",
    "# CDI word columns start after metadata\n",
    "metadata_cols = [\n",
    "    \"child_id\",\"study id\",\"study\",\"gender\",\"age\",\"birthday\",\n",
    "    \"session_date\",\"session_num\",\"total num sessions\",\n",
    "    \"words_spoken\",\"items excluded\",\"percentile\",\n",
    "    \"extra categories\",\"revision\",\"languages\",\n",
    "    \"num languages\",\"cdi type\",\"hard of hearing\",\"deleted\", \"child_column_id\", \n",
    "    \"first_session_num\", \"late_talker\",\"last_session_num\",\t\"late_bloomer\",\t\"plt\",\t\"class\",\t\n",
    "    \"typical_talker\",\t\"group\"\n",
    "]\n",
    "\n",
    "word_cols = [c for c in cdi.columns if c not in metadata_cols]\n",
    "\n",
    "known_words = {w for w in word_cols if row[w] == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8424f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known_words count: 94\n",
      "total words count: 691\n"
     ]
    }
   ],
   "source": [
    "# count known words\n",
    "num = len(known_words)\n",
    "print(\"known_words count:\", num)\n",
    "\n",
    "num_tot = len(word_cols)\n",
    "print(\"total words count:\", num_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb48316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child_edges count: 3\n",
      "sample edges: [('banana', 'bread'), ('bread', 'cookie'), ('hat', 'shirt')]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# build list of edges where similarity >= SIM_THRESHOLD, in the variable `child_edges`\n",
    "child_edges = []\n",
    "for w1, w2 in itertools.combinations(sorted(known_words), 2):\n",
    "    try:\n",
    "        if sim.loc[w1, w2] >= SIM_THRESHOLD:    # similarity threshold\n",
    "            child_edges.append((w1, w2)) # add to list if similarity >= threshold\n",
    "    except KeyError:\n",
    "        # skip if either word not found in similarity matrix\n",
    "        continue\n",
    "\n",
    "print(\"child_edges count:\", len(child_edges))\n",
    "print(\"sample edges:\", child_edges[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28bf764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_words edges: 188\n",
      "   word1       word2\n",
      "0  ankle      street\n",
      "1   aunt  babysitter\n",
      "2   aunt        lady\n",
      "3   aunt         man\n",
      "4   aunt       woman\n",
      "Saved all_words.txt to: /Users/abbyhultquist/Documents/First Year Project/all_words.txt\n"
     ]
    }
   ],
   "source": [
    "all_words_df = pd.DataFrame(edges, columns=[\"word1\", \"word2\"])\n",
    "print(\"all_words edges:\", len(all_words_df))\n",
    "print(all_words_df.head())\n",
    "\n",
    "# write to file (NO header, NO index)\n",
    "all_words_path = \"/Users/abbyhultquist/Documents/First Year Project/all_words.txt\"\n",
    "all_words_df.to_csv(all_words_path, index=False, header=False)\n",
    "\n",
    "print(\"Saved all_words.txt to:\", all_words_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47277260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child_vocab edges: 3\n",
      "    word1   word2\n",
      "0  banana   bread\n",
      "1   bread  cookie\n",
      "2     hat   shirt\n",
      "Saved child vocabulary file to: /Users/abbyhultquist/Documents/First Year Project/child_vocab_4139_s1.txt\n"
     ]
    }
   ],
   "source": [
    "child_vocab_df = pd.DataFrame(child_edges, columns=[\"word1\", \"word2\"])\n",
    "\n",
    "print(\"child_vocab edges:\", len(child_vocab_df))\n",
    "print(child_vocab_df.head())\n",
    "\n",
    "child_vocab_path = f\"/Users/abbyhultquist/Documents/First Year Project/child_vocab_{child_id}_s{session_num}.txt\"\n",
    "\n",
    "child_vocab_df.to_csv(child_vocab_path, index=False, header=False)\n",
    "\n",
    "print(\"Saved child vocabulary file to:\", child_vocab_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11e43f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words in child network: 5\n",
      "isolated known words (no edges): 89\n"
     ]
    }
   ],
   "source": [
    "# how many unique words does the child network contain?\n",
    "child_words_in_edges = set(child_vocab_df[\"word1\"]).union(child_vocab_df[\"word2\"])\n",
    "print(\"unique words in child network:\", len(child_words_in_edges))\n",
    "\n",
    "# words known but isolated (no semantic edges)\n",
    "isolated_words = known_words - child_words_in_edges\n",
    "print(\"isolated known words (no edges):\", len(isolated_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba1be25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial CDI shape: (1167, 699)\n",
      "total # words considered: 680\n",
      "Initial vocab_size calculated\n",
      "After removing children with <4 sessions: (1154, 700)\n",
      "Removed 11 children with < 4 sessions\n",
      "Removed 1 additional outlier children:\n",
      "  - 1 for session_num > 12\n",
      "  - 0 for vocab_size > # words in CDI\n",
      "  - 0 for zscore > 3 on vocab_size\n",
      "After removing outliers: (1141, 700)\n",
      "\n",
      "After ensuring cumulative knowledge and recalculating vocab_size\n",
      "Sample vocab_size stats: count    1141.000000\n",
      "mean      318.234005\n",
      "std       221.384675\n",
      "min         0.000000\n",
      "25%       105.000000\n",
      "50%       305.000000\n",
      "75%       523.000000\n",
      "max       682.000000\n",
      "Name: vocab_size, dtype: float64\n",
      "Updated words_spoken to match cumulative vocab_size\n",
      "Late Talkers: 41\n",
      "Persistent Late Talkers: 9\n",
      "Late Bloomers: 32\n",
      "Final CDI shape: (1141, 702)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#Cleaning CDI Data\n",
    "CDI_raw = pd.read_csv(\"/Users/abbyhultquist/Documents/First Year Project/CDI_raw.csv\")\n",
    "CDI = CDI_raw.copy()\n",
    "\n",
    "print(\"Initial CDI shape:\", CDI.shape)\n",
    "CDI = CDI.sort_values(['child_id', 'session_num'])\n",
    "\n",
    "\n",
    "\n",
    "#creating a list of ALL words \n",
    "word_cols = CDI.columns[19:].tolist()\n",
    "metadata_cols = CDI.columns[:19].tolist()\n",
    "\n",
    "print(\"total # words considered:\", len(word_cols))\n",
    "\n",
    "# Calculate initial vocab_size\n",
    "CDI['vocab_size'] = CDI[word_cols].sum(axis=1)\n",
    "print(\"Initial vocab_size calculated\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Remove children with less than 4 sessions\n",
    "session_counts = CDI.groupby('child_id')['session_num'].count()\n",
    "valid_children = session_counts[session_counts >= 4].index\n",
    "CDI = CDI[CDI['child_id'].isin(valid_children)]\n",
    "\n",
    "print(f\"After removing children with <4 sessions: {CDI.shape}\")\n",
    "print(f\"Removed {len(session_counts) - len(valid_children)} children with < 4 sessions\")\n",
    "\n",
    "\n",
    "# Find and remove outliers\n",
    "outliers_sessions = set(CDI[CDI['session_num'] > 12]['child_id'])\n",
    "outliers_vocab = set(CDI[CDI['words_spoken'] > len(word_cols)]['child_id'])\n",
    "z_scores = stats.zscore(CDI['words_spoken'])\n",
    "outliers_zscore = set(CDI[np.abs(z_scores) > 3]['child_id'])\n",
    "\n",
    "all_outliers = outliers_sessions | outliers_vocab | outliers_zscore\n",
    "\n",
    "print(f\"Removed {len(all_outliers)} additional outlier children:\")\n",
    "print(f\"  - {len(outliers_sessions)} for session_num > 12\")\n",
    "print(f\"  - {len(outliers_vocab)} for vocab_size > # words in CDI\")\n",
    "print(f\"  - {len(outliers_zscore)} for zscore > 3 on vocab_size\")\n",
    "\n",
    "CDI = CDI[~CDI['child_id'].isin(all_outliers)].copy()\n",
    "\n",
    "print(f\"After removing outliers: {CDI.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Once a word is learned, it stays learned\n",
    "grouped = CDI.groupby('child_id')\n",
    "for child_id, group in grouped:\n",
    "    group = group.sort_values('session_num')\n",
    "    for word in word_cols:\n",
    "        # Find first session where word is known\n",
    "        known_sessions = group[group[word] == 1]['session_num']\n",
    "        if not known_sessions.empty:\n",
    "            first_known = known_sessions.min()\n",
    "            # Set word as known from first_known onwards\n",
    "            CDI.loc[(CDI['child_id'] == child_id) & (CDI['session_num'] >= first_known), word] = 1\n",
    "# Update words_spoken to reflect the cumulative knowledge\n",
    "CDI['words_spoken'] = CDI[word_cols].sum(axis=1)\n",
    "\n",
    "# Also update vocab_size\n",
    "CDI['vocab_size'] = CDI['words_spoken']\n",
    "\n",
    "print()\n",
    "print(\"After ensuring cumulative knowledge and recalculating vocab_size\")\n",
    "print(\"Sample vocab_size stats:\", CDI['vocab_size'].describe())\n",
    "print(\"Updated words_spoken to match cumulative vocab_size\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#defining late talkers (0 = TT, 1 = LT)\n",
    "#defining PLT (0 = Late bloomer, 1 = PLT, NA means they are a TT)\n",
    "CDI[\"Late_Talker\"] = 0\n",
    "CDI[\"Persistent_Late_Talker\"] = np.nan #Only LT get set to 0 or 1\n",
    "\n",
    "grouped = CDI.groupby('child_id')\n",
    "\n",
    "for child_id, group in grouped:\n",
    "    first_session = group['session_num'].min()\n",
    "    last_session = group['session_num'].max()\n",
    "    \n",
    "    # Check first session for this child\n",
    "    first_session_data = group[group['session_num'] == first_session]\n",
    "    \n",
    "    if len(first_session_data) > 0:\n",
    "        if first_session_data['percentile'].values[0] < 20:\n",
    "            CDI.loc[CDI['child_id'] == child_id, 'Late_Talker'] = 1\n",
    "        else:\n",
    "            CDI.loc[CDI['child_id'] == child_id, 'Late_Talker'] = 0\n",
    "    \n",
    "    # Check last session for this child\n",
    "    last_session_data = group[group['session_num'] == last_session]\n",
    "    \n",
    "    if len(last_session_data) > 0:\n",
    "        late_talker_status = CDI.loc[CDI['child_id'] == child_id, 'Late_Talker'].values[0]\n",
    "        \n",
    "        if late_talker_status == 1:  # Was a late talker\n",
    "            if last_session_data['percentile'].values[0] < 20:  # FIXED: Still below 20%\n",
    "                CDI.loc[CDI['child_id'] == child_id, 'Persistent_Late_Talker'] = 1\n",
    "            else:  # Improved (late bloomer)\n",
    "                CDI.loc[CDI['child_id'] == child_id, 'Persistent_Late_Talker'] = 0\n",
    "        else:  # Not a late talker\n",
    "            CDI.loc[CDI['child_id'] == child_id, 'Persistent_Late_Talker'] = np.nan  # FIXED: Use np.nan\n",
    "\n",
    "# Verify \n",
    "print(\"Late Talkers:\", CDI[CDI['Late_Talker'] == 1]['child_id'].nunique())\n",
    "print(\"Persistent Late Talkers:\", CDI[CDI['Persistent_Late_Talker'] == 1]['child_id'].nunique())\n",
    "print(\"Late Bloomers:\", CDI[(CDI['Late_Talker'] == 1) & (CDI['Persistent_Late_Talker'] == 0)]['child_id'].nunique())\n",
    "\n",
    "print(\"Final CDI shape:\", CDI.shape)\n",
    "\n",
    "# Reorder columns: metadata, added columns, word columns\n",
    "added_cols = ['vocab_size', 'Late_Talker', 'Persistent_Late_Talker']\n",
    "new_order = metadata_cols + added_cols + word_cols\n",
    "CDI = CDI[new_order]\n",
    "\n",
    "CDI.to_csv('CDI_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123a8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import tkinter as tkinter\n",
    "from tkinter import filedialog as tkfiledialog\n",
    "\n",
    "ENTRY_WIDTH = 20\n",
    "\n",
    "\n",
    "def browse_for_entry(entry_box, dialog_type, filetype):\n",
    "    if dialog_type == \"open\":\n",
    "        name = tkfiledialog.askopenfilename(filetypes=[filetype])\n",
    "    else:\n",
    "        name = tkfiledialog.asksaveasfilename(filetypes=[filetype])\n",
    "    entry_box.delete(0, tkinter.END)\n",
    "    entry_box.insert(0, name)\n",
    "\n",
    "\n",
    "def show_finished(status_label, run_button):\n",
    "    run_button.configure(text=\"Run Again\", state=tkinter.NORMAL)\n",
    "    status_label.configure(text=\"Done.\")\n",
    "\n",
    "\n",
    "def run_dummy(status_label, run_button):\n",
    "    # placeholder for now\n",
    "    status_label.configure(text=\"Pretend model ran âœ”\")\n",
    "    show_finished(status_label, run_button)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    master = tkinter.Tk()\n",
    "    master.title(\"Growth Model Runner\")\n",
    "\n",
    "    tkinter.Label(master, text=\"Child vocabulary:\").grid(row=0, column=0, sticky=tkinter.E)\n",
    "    tkinter.Label(master, text=\"All words:\").grid(row=1, column=0, sticky=tkinter.E)\n",
    "    tkinter.Label(master, text=\"Output summary:\").grid(row=2, column=0, sticky=tkinter.E)\n",
    "\n",
    "    child_vocab_entry = tkinter.Entry(master, width=40)\n",
    "    child_vocab_entry.grid(row=0, column=1)\n",
    "\n",
    "    all_words_entry = tkinter.Entry(master, width=40)\n",
    "    all_words_entry.grid(row=1, column=1)\n",
    "\n",
    "    output_entry = tkinter.Entry(master, width=40)\n",
    "    output_entry.grid(row=2, column=1)\n",
    "\n",
    "    tkinter.Button(\n",
    "        master, text=\"Browse\",\n",
    "        command=lambda: browse_for_entry(child_vocab_entry, \"open\", (\"Text files\", \".txt\"))\n",
    "    ).grid(row=0, column=2)\n",
    "\n",
    "    tkinter.Button(\n",
    "        master, text=\"Browse\",\n",
    "        command=lambda: browse_for_entry(all_words_entry, \"open\", (\"Text files\", \".txt\"))\n",
    "    ).grid(row=1, column=2)\n",
    "\n",
    "    tkinter.Button(\n",
    "        master, text=\"Browse\",\n",
    "        command=lambda: browse_for_entry(output_entry, \"saveas\", (\"CSV files\", \".csv\"))\n",
    "    ).grid(row=2, column=2)\n",
    "\n",
    "    status_label = tkinter.Label(master, text=\"Ready\", width=ENTRY_WIDTH)\n",
    "    status_label.grid(row=4, column=0, columnspan=3)\n",
    "\n",
    "    run_button = tkinter.Button(\n",
    "        master, text=\"Run Growth\",\n",
    "        command=lambda: run_dummy(status_label, run_button)\n",
    "    )\n",
    "    run_button.grid(row=3, column=0, columnspan=3, sticky=tkinter.E+tkinter.W)\n",
    "\n",
    "    master.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
